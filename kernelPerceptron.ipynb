{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from numba import jit\n",
    "from sklearn.model_selection import KFold\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(('zipcombo.dat'))\n",
    "num_labels = len(set(data[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def poly_kernel(data, vec, d):\n",
    "    '''\n",
    "    INPUTS:\n",
    "    data:       (#points,#pixels) matrix of data points (labels taken off)\n",
    "    vec:        (#pixels,) vector to calculate kernel of\n",
    "    d:          polynomial exponent\n",
    "    OUTPUT:\n",
    "    val:        (#points,) vector of kernel values with each training point\n",
    "    '''\n",
    "\n",
    "    val = (data @ vec.reshape(-1,1))**d\n",
    "    return val.ravel()\n",
    "\n",
    "def class_pred(data, vec, alphas, d):\n",
    "    '''\n",
    "    INPUTS:\n",
    "    data:       (#points,#pixels) matrix of data points (labels taken off)\n",
    "    vec:        (#pixels,) vector to calculate kernel of\n",
    "    d:          polynomial exponent\n",
    "    alphas:     (#labels,#points) matrix of values of alpha in the dual problem\n",
    "    OUTPUT:\n",
    "    preds:      (#labels,) vector of predictions for each label \n",
    "    '''\n",
    "    kervals = poly_kernel(data,vec,d)\n",
    "    preds = alphas @ kervals.reshape(-1,1)\n",
    "    return preds.ravel()\n",
    "\n",
    "def init_alphas(data):\n",
    "    alphas = np.zeros((10,int(len(data))))\n",
    "    return alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training algorithm:\n",
    "#have num_label individual classifiers which each classify whether it is or isnt that label\n",
    "#on each point, we see how the classifier predicts, and update each classifier's coefficients which made a mistake\n",
    "#the overall classifier's prediction is the classifier with the largest prediction \n",
    "\n",
    "def train_perceptron(data, alphas, d):\n",
    "    '''\n",
    "    INPUTS:\n",
    "    data:        (#points,#pixels+1) matrix of data points\n",
    "    alphas:      (#labels,#points) matrix of values of alpha in the dual problem\n",
    "    d:           polynomial exponent\n",
    "    OUTPUT:\n",
    "    error_rate, alphas\n",
    "    '''\n",
    "    mistakes = 0\n",
    "    #for each training point\n",
    "    for i in range(len(data)):\n",
    "        label = data[i,0]\n",
    "\n",
    "        #obtain prediction made by each classifier\n",
    "        preds = class_pred(data[:,1:],data[i,1:],alphas,d)\n",
    "        preds_binary = np.where(preds <= 0, -1, 1)\n",
    "\n",
    "        #check which classifier made a mistake\n",
    "        truth_col = -np.ones(num_labels)\n",
    "        truth_col[int(label)] = 1\n",
    "        is_pred_wrong = (preds_binary != truth_col).astype(np.int32)          #a vector which has a 1 if the kth classifier was wrong\n",
    "\n",
    "        #update alpha\n",
    "        alphas[:,i] -= is_pred_wrong*preds_binary\n",
    "\n",
    "        #add mistake\n",
    "        if np.argmax(preds) != label:\n",
    "            mistakes += 1\n",
    "    \n",
    "    error_rate = mistakes/len(data)\n",
    "    return error_rate, alphas\n",
    "\n",
    "\n",
    "#testing algorithm\n",
    "def test_perceptron(train, test, alphas, d, calc_conf=False):\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    mistakes = 0\n",
    "    conf_mat = np.zeros((10,10))\n",
    "    \n",
    "    for i in range(len(test)):\n",
    "        label = test[i,0]\n",
    "        preds = class_pred(train[:,1:],test[i,1:],alphas,d)\n",
    "        if int(np.argmax(preds)) != int(label):\n",
    "            mistakes += 1\n",
    "            if calc_conf:\n",
    "                conf_mat[int(label),int(np.argmax(preds))] += 1\n",
    "\n",
    "    #normalise conf_mat\n",
    "    if calc_conf:\n",
    "        label_counts = np.bincount(test[:,0].astype(int),minlength=10)\n",
    "        label_counts[label_counts==0] = 1\n",
    "        label_counts = label_counts.reshape(-1,1)\n",
    "\n",
    "        #turn it into a rate\n",
    "        conf_mat = conf_mat / label_counts\n",
    "\n",
    "    error_rate = mistakes/len(test)\n",
    "\n",
    "    if calc_conf:\n",
    "        return error_rate, conf_mat  \n",
    "    else:\n",
    "        return error_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def demo(train, test, d):\n",
    "#     alpha_list = init_alphas(train)\n",
    "#     for i in range(3):  # 3 iterations chosen arbitrarily\n",
    "#         mistakes, alpha_list = train_perceptron(train, alpha_list, d)\n",
    "#         print(f\"Training - epoch {i+1} with {mistakes} mistakes out of {len(train)} items.\")\n",
    "#         test_error, conf_mat = test_perceptron(train, test, alpha_list, d, calc_conf=True)\n",
    "#         print(f\"Testing - epoch {i+1} with a test error of {test_error*100:.3f}%.\")\n",
    "\n",
    "# train_indices = np.arange(8000)\n",
    "# train_data = data[train_indices,:]\n",
    "# test_data = data[-train_indices,:]\n",
    "\n",
    "# demo(train_data,test_data,d=3)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Testing values of d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating run 1 for power 1.\n",
      "Calculating run 2 for power 1.\n",
      "Calculating run 3 for power 1.\n",
      "Calculating run 4 for power 1.\n",
      "Calculating run 5 for power 1.\n",
      "Calculating run 6 for power 1.\n",
      "Calculating run 7 for power 1.\n",
      "Calculating run 8 for power 1.\n",
      "Calculating run 9 for power 1.\n",
      "Calculating run 10 for power 1.\n",
      "Calculating run 11 for power 1.\n",
      "Calculating run 12 for power 1.\n",
      "Calculating run 13 for power 1.\n",
      "Calculating run 14 for power 1.\n",
      "Calculating run 15 for power 1.\n",
      "Calculating run 16 for power 1.\n",
      "Calculating run 17 for power 1.\n",
      "Calculating run 18 for power 1.\n",
      "Calculating run 19 for power 1.\n",
      "Calculating run 20 for power 1.\n",
      "Calculating run 1 for power 2.\n",
      "Calculating run 2 for power 2.\n",
      "Calculating run 3 for power 2.\n",
      "Calculating run 4 for power 2.\n",
      "Calculating run 5 for power 2.\n",
      "Calculating run 6 for power 2.\n",
      "Calculating run 7 for power 2.\n",
      "Calculating run 8 for power 2.\n",
      "Calculating run 9 for power 2.\n",
      "Calculating run 10 for power 2.\n",
      "Calculating run 11 for power 2.\n",
      "Calculating run 12 for power 2.\n",
      "Calculating run 13 for power 2.\n",
      "Calculating run 14 for power 2.\n",
      "Calculating run 15 for power 2.\n",
      "Calculating run 16 for power 2.\n",
      "Calculating run 17 for power 2.\n",
      "Calculating run 18 for power 2.\n",
      "Calculating run 19 for power 2.\n",
      "Calculating run 20 for power 2.\n",
      "Calculating run 1 for power 3.\n",
      "Calculating run 2 for power 3.\n",
      "Calculating run 3 for power 3.\n",
      "Calculating run 4 for power 3.\n",
      "Calculating run 5 for power 3.\n",
      "Calculating run 6 for power 3.\n",
      "Calculating run 7 for power 3.\n",
      "Calculating run 8 for power 3.\n",
      "Calculating run 9 for power 3.\n",
      "Calculating run 10 for power 3.\n",
      "Calculating run 11 for power 3.\n",
      "Calculating run 12 for power 3.\n",
      "Calculating run 13 for power 3.\n",
      "Calculating run 14 for power 3.\n",
      "Calculating run 15 for power 3.\n",
      "Calculating run 16 for power 3.\n",
      "Calculating run 17 for power 3.\n",
      "Calculating run 18 for power 3.\n",
      "Calculating run 19 for power 3.\n",
      "Calculating run 20 for power 3.\n",
      "Calculating run 1 for power 4.\n",
      "Calculating run 2 for power 4.\n",
      "Calculating run 3 for power 4.\n",
      "Calculating run 4 for power 4.\n",
      "Calculating run 5 for power 4.\n",
      "Calculating run 6 for power 4.\n",
      "Calculating run 7 for power 4.\n",
      "Calculating run 8 for power 4.\n",
      "Calculating run 9 for power 4.\n",
      "Calculating run 10 for power 4.\n",
      "Calculating run 11 for power 4.\n",
      "Calculating run 12 for power 4.\n",
      "Calculating run 13 for power 4.\n",
      "Calculating run 14 for power 4.\n",
      "Calculating run 15 for power 4.\n",
      "Calculating run 16 for power 4.\n",
      "Calculating run 17 for power 4.\n",
      "Calculating run 18 for power 4.\n",
      "Calculating run 19 for power 4.\n",
      "Calculating run 20 for power 4.\n",
      "Calculating run 1 for power 5.\n",
      "Calculating run 2 for power 5.\n",
      "Calculating run 3 for power 5.\n",
      "Calculating run 4 for power 5.\n",
      "Calculating run 5 for power 5.\n",
      "Calculating run 6 for power 5.\n",
      "Calculating run 7 for power 5.\n",
      "Calculating run 8 for power 5.\n",
      "Calculating run 9 for power 5.\n",
      "Calculating run 10 for power 5.\n",
      "Calculating run 11 for power 5.\n",
      "Calculating run 12 for power 5.\n",
      "Calculating run 13 for power 5.\n",
      "Calculating run 14 for power 5.\n",
      "Calculating run 15 for power 5.\n",
      "Calculating run 16 for power 5.\n",
      "Calculating run 17 for power 5.\n",
      "Calculating run 18 for power 5.\n",
      "Calculating run 19 for power 5.\n",
      "Calculating run 20 for power 5.\n",
      "Calculating run 1 for power 6.\n",
      "Calculating run 2 for power 6.\n",
      "Calculating run 3 for power 6.\n",
      "Calculating run 4 for power 6.\n",
      "Calculating run 5 for power 6.\n",
      "Calculating run 6 for power 6.\n",
      "Calculating run 7 for power 6.\n",
      "Calculating run 8 for power 6.\n",
      "Calculating run 9 for power 6.\n",
      "Calculating run 10 for power 6.\n",
      "Calculating run 11 for power 6.\n",
      "Calculating run 12 for power 6.\n",
      "Calculating run 13 for power 6.\n",
      "Calculating run 14 for power 6.\n",
      "Calculating run 15 for power 6.\n",
      "Calculating run 16 for power 6.\n",
      "Calculating run 17 for power 6.\n",
      "Calculating run 18 for power 6.\n",
      "Calculating run 19 for power 6.\n",
      "Calculating run 20 for power 6.\n",
      "Calculating run 1 for power 7.\n",
      "Calculating run 2 for power 7.\n",
      "Calculating run 3 for power 7.\n",
      "Calculating run 4 for power 7.\n",
      "Calculating run 5 for power 7.\n",
      "Calculating run 6 for power 7.\n",
      "Calculating run 7 for power 7.\n",
      "Calculating run 8 for power 7.\n",
      "Calculating run 9 for power 7.\n",
      "Calculating run 10 for power 7.\n",
      "Calculating run 11 for power 7.\n",
      "Calculating run 12 for power 7.\n",
      "Calculating run 13 for power 7.\n",
      "Calculating run 14 for power 7.\n",
      "Calculating run 15 for power 7.\n",
      "Calculating run 16 for power 7.\n",
      "Calculating run 17 for power 7.\n",
      "Calculating run 18 for power 7.\n",
      "Calculating run 19 for power 7.\n",
      "Calculating run 20 for power 7.\n"
     ]
    }
   ],
   "source": [
    "random.seed(1)\n",
    "\n",
    "def train_test(data, d):\n",
    "    shuffled_data = np.random.permutation(data)\n",
    "\n",
    "    split_idx = int(len(data) * 0.8)\n",
    "\n",
    "    train = shuffled_data[:split_idx, :]\n",
    "    test = shuffled_data[split_idx:, :]\n",
    "\n",
    "    alpha_list = init_alphas(train)\n",
    "\n",
    "    train_error, alpha_list = train_perceptron(train, alpha_list, d)\n",
    "    test_error = test_perceptron(train, test, alpha_list, d)\n",
    "\n",
    "    return train_error, test_error\n",
    "\n",
    "#results stored: dim1=d, dim2=run, dim3=train/test\n",
    "results = np.zeros((7,20,2))\n",
    "\n",
    "for d in range(7):\n",
    "    for i in range(20):\n",
    "        print(f'Calculating run {i+1} for power {d+1}.')\n",
    "        results[d,i,0], results[d,i,1] = train_test(data,d+1) \n",
    "\n",
    "np.save('results1.npy', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_loaded = np.load('results1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.1469481 , 0.12473118],\n",
       "        [0.14869589, 0.10752688],\n",
       "        [0.1445281 , 0.15591398],\n",
       "        [0.14708255, 0.09623656],\n",
       "        [0.14708255, 0.09032258],\n",
       "        [0.14748588, 0.12043011],\n",
       "        [0.14775477, 0.09516129],\n",
       "        [0.14815811, 0.1016129 ],\n",
       "        [0.14923366, 0.10806452],\n",
       "        [0.14923366, 0.11182796],\n",
       "        [0.14909922, 0.11989247],\n",
       "        [0.14869589, 0.11236559],\n",
       "        [0.14493143, 0.09139785],\n",
       "        [0.14479699, 0.12580645],\n",
       "        [0.14802366, 0.11612903],\n",
       "        [0.14278032, 0.15215054],\n",
       "        [0.1418392 , 0.10967742],\n",
       "        [0.14049476, 0.1344086 ],\n",
       "        [0.14210809, 0.13817204],\n",
       "        [0.14197365, 0.18978495]],\n",
       "\n",
       "       [[0.09290132, 0.06612903],\n",
       "        [0.09209465, 0.05913978],\n",
       "        [0.09142243, 0.05752688],\n",
       "        [0.08927131, 0.06290323],\n",
       "        [0.0946491 , 0.06129032],\n",
       "        [0.0946491 , 0.05053763],\n",
       "        [0.09128798, 0.06129032],\n",
       "        [0.09680022, 0.06290323],\n",
       "        [0.09438021, 0.06021505],\n",
       "        [0.09290132, 0.05591398],\n",
       "        [0.09438021, 0.05053763],\n",
       "        [0.09007798, 0.06290323],\n",
       "        [0.09787577, 0.05537634],\n",
       "        [0.098548  , 0.07526882],\n",
       "        [0.09599355, 0.05322581],\n",
       "        [0.09693466, 0.0688172 ],\n",
       "        [0.09895133, 0.0483871 ],\n",
       "        [0.09384243, 0.04892473],\n",
       "        [0.09088465, 0.07903226],\n",
       "        [0.09155687, 0.06021505]],\n",
       "\n",
       "       [[0.07690239, 0.04301075],\n",
       "        [0.08362463, 0.04086022],\n",
       "        [0.07999462, 0.05268817],\n",
       "        [0.08080129, 0.03387097],\n",
       "        [0.08308685, 0.06612903],\n",
       "        [0.07891906, 0.04784946],\n",
       "        [0.07905351, 0.04623656],\n",
       "        [0.07851573, 0.04946237],\n",
       "        [0.07676795, 0.04569892],\n",
       "        [0.08039796, 0.03763441],\n",
       "        [0.0817424 , 0.05860215],\n",
       "        [0.08107018, 0.0344086 ],\n",
       "        [0.07905351, 0.04677419],\n",
       "        [0.07649906, 0.0516129 ],\n",
       "        [0.08133907, 0.05376344],\n",
       "        [0.07891906, 0.04354839],\n",
       "        [0.07959129, 0.04247312],\n",
       "        [0.08308685, 0.05645161],\n",
       "        [0.07878462, 0.05376344],\n",
       "        [0.07528906, 0.03548387]],\n",
       "\n",
       "       [[0.07407905, 0.04462366],\n",
       "        [0.07394461, 0.04623656],\n",
       "        [0.07165905, 0.04569892],\n",
       "        [0.07139016, 0.04032258],\n",
       "        [0.07367572, 0.03817204],\n",
       "        [0.07286905, 0.04193548],\n",
       "        [0.07192794, 0.04892473],\n",
       "        [0.06870126, 0.04354839],\n",
       "        [0.07139016, 0.04139785],\n",
       "        [0.0703146 , 0.04569892],\n",
       "        [0.06977682, 0.04946237],\n",
       "        [0.07703684, 0.04193548],\n",
       "        [0.07555795, 0.04032258],\n",
       "        [0.07112127, 0.04462366],\n",
       "        [0.07515461, 0.04032258],\n",
       "        [0.07569239, 0.06505376],\n",
       "        [0.07273461, 0.03602151],\n",
       "        [0.07394461, 0.04247312],\n",
       "        [0.07273461, 0.04731183],\n",
       "        [0.07286905, 0.05107527]],\n",
       "\n",
       "       [[0.07018016, 0.03978495],\n",
       "        [0.0691046 , 0.03602151],\n",
       "        [0.0703146 , 0.0483871 ],\n",
       "        [0.07098682, 0.04462366],\n",
       "        [0.07071793, 0.03870968],\n",
       "        [0.07112127, 0.04731183],\n",
       "        [0.07085238, 0.03709677],\n",
       "        [0.07394461, 0.05376344],\n",
       "        [0.07260016, 0.05      ],\n",
       "        [0.07018016, 0.04139785],\n",
       "        [0.06964238, 0.05      ],\n",
       "        [0.07260016, 0.04731183],\n",
       "        [0.07139016, 0.03817204],\n",
       "        [0.07233127, 0.03655914],\n",
       "        [0.07058349, 0.04032258],\n",
       "        [0.07125571, 0.03924731],\n",
       "        [0.07219683, 0.04731183],\n",
       "        [0.07085238, 0.04032258],\n",
       "        [0.0703146 , 0.03817204],\n",
       "        [0.07018016, 0.04354839]],\n",
       "\n",
       "       [[0.07018016, 0.04569892],\n",
       "        [0.07286905, 0.03655914],\n",
       "        [0.07192794, 0.03709677],\n",
       "        [0.07246572, 0.03763441],\n",
       "        [0.0703146 , 0.04086022],\n",
       "        [0.07502017, 0.03333333],\n",
       "        [0.0730035 , 0.03602151],\n",
       "        [0.07058349, 0.03709677],\n",
       "        [0.07139016, 0.03494624],\n",
       "        [0.07609572, 0.03602151],\n",
       "        [0.07139016, 0.05      ],\n",
       "        [0.07179349, 0.04139785],\n",
       "        [0.07044905, 0.03763441],\n",
       "        [0.07407905, 0.03817204],\n",
       "        [0.07179349, 0.04247312],\n",
       "        [0.07112127, 0.04462366],\n",
       "        [0.07394461, 0.03225806],\n",
       "        [0.07246572, 0.03763441],\n",
       "        [0.07260016, 0.04086022],\n",
       "        [0.07233127, 0.04569892]],\n",
       "\n",
       "       [[0.07434794, 0.04569892],\n",
       "        [0.07434794, 0.03494624],\n",
       "        [0.07260016, 0.04193548],\n",
       "        [0.07327239, 0.03924731],\n",
       "        [0.07340683, 0.03978495],\n",
       "        [0.06937349, 0.04301075],\n",
       "        [0.0742135 , 0.04301075],\n",
       "        [0.07649906, 0.03548387],\n",
       "        [0.07434794, 0.04032258],\n",
       "        [0.0703146 , 0.04139785],\n",
       "        [0.07381016, 0.03602151],\n",
       "        [0.07165905, 0.04086022],\n",
       "        [0.07192794, 0.03870968],\n",
       "        [0.07219683, 0.03602151],\n",
       "        [0.07058349, 0.04677419],\n",
       "        [0.0730035 , 0.04677419],\n",
       "        [0.07125571, 0.04193548],\n",
       "        [0.07609572, 0.04032258],\n",
       "        [0.0742135 , 0.03655914],\n",
       "        [0.07555795, 0.03978495]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Cross-validation and 3. Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit\n",
    "\n",
    "def cross_val(data, d, k=5):\n",
    "    kf = KFold(n_splits=k)\n",
    "    score = np.zeros(k)\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kf.split(data)):\n",
    "        train_cv = data[train_index,:]\n",
    "        test_cv = data[test_index,:]\n",
    "\n",
    "        alpha_cv = init_alphas(train_cv)\n",
    "            \n",
    "        _, alpha_cv = train_perceptron(train_cv, alpha_cv, d+1)\n",
    "        test_error = test_perceptron(train_cv, test_cv, alpha_cv, d+1)\n",
    "\n",
    "        score[i] = test_error\n",
    "    \n",
    "    return score.mean()\n",
    "     \n",
    "\n",
    "def train_with_d_star(data):\n",
    "    #split training and test\n",
    "    shuffled_data = np.random.permutation(data)\n",
    "\n",
    "    split_idx = int(len(data) * 0.8)\n",
    "\n",
    "    train = shuffled_data[:split_idx, :]\n",
    "    test = shuffled_data[split_idx:, :]\n",
    "\n",
    "\n",
    "\n",
    "    params = [(train, d) for d in range(1, 8)]\n",
    "\n",
    "    # Parallelize the cross-validation for different d values\n",
    "    with mp.Pool() as pool:\n",
    "        test_score = np.array(pool.starmap(cross_val, params))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # #cross validate to find best d\n",
    "    # test_score = np.array([cross_val(train, d) for d in range(1,8)])\n",
    "    \n",
    "    d_star = np.argmin(test_score) + 1\n",
    "\n",
    "    #train perceptron with d_star\n",
    "    alpha_list = init_alphas(train)\n",
    "\n",
    "    _, alpha_list = train_perceptron(train, alpha_list, d_star)\n",
    "    test_error, conf_mat = test_perceptron(train, test, alpha_list, d_star, calc_conf=True)\n",
    "\n",
    "    return d_star, test_error, conf_mat\n",
    "\n",
    "\n",
    "with mp.Pool() as pool:\n",
    "    results = pool.map(train_with_d_star, [data]*20)\n",
    "\n",
    "    # Initialize arrays to store the results\n",
    "d_star_list = np.zeros(20)\n",
    "test_error_list = np.zeros(20)\n",
    "conf_mat_list = np.zeros((20,10,10))  # Adjust dimensions as necessary\n",
    "\n",
    "    # Unpack and store the results in the arrays\n",
    "for i, (d_star, test_error, conf_mat) in enumerate(results):\n",
    "    d_star_list[i] = d_star\n",
    "    test_error_list[i] = test_error\n",
    "    conf_mat_list[i] = conf_mat\n",
    "\n",
    "    # Save the results\n",
    "np.save('d_star_list2.npy', d_star_list)\n",
    "np.save('test_error_list2.npy', test_error_list)\n",
    "np.save('conf_mat_list2.npy', conf_mat_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# d_star_list = np.zeros(20)\n",
    "# test_error_list = np.zeros(20)\n",
    "# conf_mat_list = np.zeros((20,10,10))\n",
    "        \n",
    "# for i in range(20):\n",
    "#     d_star, test_error, conf_mat = train_with_d_star(data)\n",
    "#     d_star_list[i] = d_star\n",
    "#     test_error_list[i] = test_error\n",
    "#     conf_mat_list[i,:,:] = conf_mat\n",
    "\n",
    "\n",
    "# np.save('d_star_list2.npy', d_star_list)\n",
    "# np.save('test_error_list2.npy', test_error_list)\n",
    "# np.save('conf_mat_list2.npy', conf_mat_list)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
